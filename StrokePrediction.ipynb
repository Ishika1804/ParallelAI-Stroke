{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rDnTqlPgg1O",
        "outputId": "3bea008b-e4fa-44f9-f4c2-877b69eb61c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                     0\n",
            "gender                 0\n",
            "age                    0\n",
            "hypertension           0\n",
            "heart_disease          0\n",
            "ever_married           0\n",
            "work_type              0\n",
            "Residence_type         0\n",
            "avg_glucose_level      0\n",
            "bmi                  201\n",
            "smoking_status         0\n",
            "stroke                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the stroke dataset\n",
        "data_path = '/content/healthcare-dataset-stroke-data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values (for example, BMI)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['bmi'] = imputer.fit_transform(df[['bmi']])\n",
        "\n",
        "# Drop any remaining missing values if needed\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert categorical variables into dummy/one-hot encoding\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('stroke', axis=1)  # Features\n",
        "y = df['stroke']  # Target variable\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "#print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sIAD4Y6g1jZ",
        "outputId": "b0b72354-de25-486c-c560-08bab947de09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1444\n",
            "           1       0.50      0.01      0.02        89\n",
            "\n",
            "    accuracy                           0.94      1533\n",
            "   macro avg       0.72      0.51      0.50      1533\n",
            "weighted avg       0.92      0.94      0.92      1533\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mpi4py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gTTlUN1g6WE",
        "outputId": "c5f5cb75-14f4-49d1-ca4c-e304d82b8f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.0.tar.gz (464 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/464.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m460.8/464.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.8/464.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4266266 sha256=9cbc4a8b986a50085c99c408b95d0c1a7031d9fd28aefc943e8e14daaf8aa85e\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mpi4py is a Python package that provides bindings to the Message Passing Interface (MPI), allowing Python programs to exploit multiple processors or nodes in a distributed computing environment. MPI is a standard for parallel programming, primarily used in high-performance computing (HPC). It enables communication between processes running on different processors or across multiple machines (nodes) in a cluster.\n",
        "\n",
        "How mpi4py Works\n",
        "MPI uses a distributed memory model, where each process has its own memory, and communication happens explicitly through message passing. mpi4py allows you to write parallel programs by managing this communication between different processes."
      ],
      "metadata": {
        "id": "ZtXOyaKJhTwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "# Split data among processes\n",
        "data_split = np.array_split(X_train_scaled, size, axis=0)\n",
        "target_split = np.array_split(y_train, size, axis=0)\n",
        "\n",
        "# Each process trains its own Logistic Regression model\n",
        "local_model = LogisticRegression()\n",
        "local_model.fit(data_split[rank], target_split[rank])\n",
        "\n",
        "# Gather predictions from all processes\n",
        "local_predictions = local_model.predict(X_test_scaled)\n",
        "gathered_predictions = comm.gather(local_predictions, root=0)\n",
        "\n",
        "if rank == 0:\n",
        "    # Combine predictions from all nodes (processes)\n",
        "    final_predictions = np.concatenate(gathered_predictions)\n",
        "    print(\"Final Accuracy:\", accuracy_score(y_test, final_predictions))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, final_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_hC3K6Qg9Ls",
        "outputId": "8e1d5f18-527c-471e-f489-4e79c2b852ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.9419439008480104\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1444\n",
            "           1       0.50      0.01      0.02        89\n",
            "\n",
            "    accuracy                           0.94      1533\n",
            "   macro avg       0.72      0.51      0.50      1533\n",
            "weighted avg       0.92      0.94      0.92      1533\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3iHykqYhaqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}